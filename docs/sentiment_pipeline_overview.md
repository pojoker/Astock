# 财经文本情绪模型的整体思路

本文档用通俗的语言解释 `code/` 目录下各类 Notebook 的共同目标、关键模块以及它们之间的差异。即便只对“预训练语言模型（BERT）”、“语义角色标注（SRL）”和“股票量化因子”有初步了解，也能借本文理清 Notebook 的工作流程。

## 1. 问题背景：为什么需要三类信息

金融新闻既包含自然语言描述，也蕴藏着对股价波动的提示。为了判断新闻的情绪（利好、利空、中性），Notebook 会综合三类信息：

1. **预训练语言模型（BERT/RoBERTa）**：它可以把整篇新闻转为上下文相关的向量表示，理解到细粒度的语义。
2. **语义角色标注（SRL）**：SRL 把一句话拆成“谁做了什么，影响了谁”，常见角色包括
   - `verb`：谓词或动作词，例如“发布”“下调”。
   - `A0`：动作的执行者（施事），如“某公司”“监管机构”。
   - `A1`：动作的对象或结果（受事/主题），如“季度盈利”“股价指引”。
   Notebook 通过这些角色，突出与事件相关的片段，而非平均处理所有单词。
3. **股票量化因子**：额外的 24 维或 299 维数值特征，描述新闻对应股票的财务指标、估值、市场状态等，帮助模型结合结构化信息判断情绪。

这三者的组合让模型既能理解文本细节，也能参考量化数据，从而更稳健地预测情绪。

## 2. 统一的数据准备流程

所有 Notebook 会重复以下步骤：

1. **读取 CSV 数据**：四个文件 `train/val/test/ood` 包含新闻正文、情绪标签、SRL 角色跨度、股票因子等列。`docs/Factor24_custom_data.md` 对格式有更详细说明。
2. **解析 SRL 字段**：把诸如 `'[(4, 2), (31, 2)]'` 的字符串转回列表，计算 `mask`，即将 `verb`、`A0`、`A1` 所在的 Token 区域标记出来。
3. **构造数据集**：`GPReviewDataset` 会同时返回文本张量、情绪标签、角色掩码和因子向量。
4. **加载预训练模型**：调用 `BertModel` 或 `RobertaModel`，把文本转成隐藏向量（通常是 `CLS` 池化向量和逐 Token 表示）。
5. **拼接额外特征**：根据不同 Notebook 的实验设置，把 SRL 汇总的向量、股票因子等与 BERT 输出组合起来，交给分类头。

## 3. 模型主体的共通结构

大多数 Notebook 中的 `SentimentClassifier`（命名可能略有不同）遵循以下逻辑：

1. **文本编码**：输入新闻文本 -> BERT 输出。
2. **角色汇聚**：利用 `mask` 取出 `verb`/`A0`/`A1` 对应的 Token 表示，再通过平均或 Transformer 层进行聚合。
3. **特征融合**：
   - 仅使用文本：直接把 BERT 池化向量送入全连接层。
   - 加入 SRL：将角色向量拼接到一起，强调与事件相关的文字。
   - 加入股票因子：把因子向量进一步拼接，使模型同时看到文本与数值特征。
4. **分类头**：经过 1–2 层全连接网络输出情绪分布（3 个类别）。
5. **损失函数**：基础版本使用交叉熵；带对比学习的 Notebook 还会额外计算 `self_pred` 或 mask 重建损失。

## 4. Notebook 之间的主要差异

虽然流程类似，但每个 Notebook 会检验不同的假设：

| Notebook 示例 | 额外特征/技巧 | 实验目的 |
| --- | --- | --- |
| `Pretrained_RoBERT.ipynb` | 只用 BERT 文本特征（虽然仍解析 SRL/因子列，但最终未送入模型） | 作为纯文本基线。 |
| `Factor24_Pretrained_ROBERT.ipynb` | 文本 + 24 因子 | 检查股票因子是否提升效果。 |
| `Factor24_Pretrained_RoBert_SRL(FC).ipynb` | 文本 + SRL 角色 + 因子 | 评估“动词/论元 + 因子”联合建模。 |
| `Pretrained_RoBert_SRL(FC)_CL(V).ipynb` | 文本 + SRL + 动词对比学习 | 让模型学会区分真实动词片段与遮蔽版本，提升动词理解。 |
| `Factor24_Pretrained_RoBert_SRL(FC)_VA0.ipynb` | 文本 + SRL + 因子 + Verb&A0 联合对比 | 观察“动词+施事”组合监督的价值。 |
| `back_test_ood.ipynb` | 使用训练好的模型预测，结合 Tushare 回测 | 关注投资收益指标而非模型训练。 |

> 表中仅列举部分文件。其它 Notebook 主要围绕“用哪一个角色做对比学习”“是否加入因子”“分类头如何调整”等小幅变化。

> **额外说明**：`Pretrained_RoBERT.ipynb` 在数据预处理阶段依旧会把 `verb`/`A0`/`A1` 的掩码和 `stock_factors` 读取出来，以便与其它 Notebook 共享同一份 CSV 解析逻辑；但在 `SentimentClassifier` 的 `forward()` 中只使用 BERT 的文本表示，并未把这些附加特征拼接进去，因此它仍是“纯文本”基线。

### 4.1 `Pretrained_RoBERT.ipynb` 与 `Factor24_Pretrained_ROBERT.ipynb` 的具体差异

| 对比点 | `Pretrained_RoBERT.ipynb` | `Factor24_Pretrained_ROBERT.ipynb` |
| --- | --- | --- |
| **模型输入** | `SentimentClassifier` 只接收 `input_ids` 与 `attention_mask`，完全依赖 BERT 的 `[CLS]` 池化向量做分类。 | 额外传入 `stock_factors` 与 `verb/A0/A1/AV_num`，虽然当前版本未对 SRL 向量做显式运算，但会处理股票因子。 |
| **因子处理方式** | 没有对应层，`forward` 直接在 BERT 池化结果上堆叠两层全连接。 | 在 `__init__` 中声明 `NUMBER_FACTOR = 24` 和 `linear_for_stock_factors`，`forward` 时把 24 维因子送入线性层并与 BERT 输出拼接，再进入分类头。 |
| **训练循环的调用方式** | `train_epoch` / `eval_model` 只向模型传入文本张量。 | 同一套循环会把 `stock_factors` 与 SRL 掩码从 DataLoader 取出并传进模型，保持与 `forward` 参数一致。 |
| **用途定位** | 纯文本基线，用于评估 BERT 单独表现。 | 在纯文本基线上叠加 24 因子，检验结构化指标对情绪识别的帮助。 |

上述差异意味着：如果你打算只使用文本特征，可直接运行 `Pretrained_RoBERT.ipynb`；若希望在预测时把 24 个股票因子也一并考虑，应选择 `Factor24_Pretrained_ROBERT.ipynb` 并确保数据集中带有 `stock_factors` 列。

## 5. 训练与推理的工作流

1. **训练阶段**
   - 迭代遍历 `train` 数据，BERT 与分类头一起更新权重。
   - 如果 Notebook 含对比损失，则在每个批次里对指定角色做遮蔽/重建，计算额外的监督信号。
   - 在 `val` 数据集评估，保存表现最好的模型权重。
2. **推理阶段**
   - 加载保存好的权重（部分 Notebook 支持跳过训练，只要指定 `RUN_TRAINING = False` 并提供 checkpoint）。
   - 对 `test` 或 `ood` 数据运行 `get_predictions()`，输出情绪概率或标签。
   - `back_test_ood.ipynb` 会继续把情绪信号转成交易策略，计算收益、回撤、夏普比率等金融指标。

## 6. 如何选择 Notebook

- **只想快速得到情绪预测**：从 `Pretrained_RoBERT.ipynb` 或 `Factor24_Pretrained_ROBERT.ipynb` 入手，步骤最少。
- **想分析 SRL 角色的重要性**：对比 `Pretrained_RoBert_SRL(FC).ipynb` 与各类 `_CL(...)`、`_A0`/`_A1` 版本，观察不同角色的贡献。
- **关注量化交易效果**：在训练好的模型基础上，打开 `back_test_ood.ipynb`，理解情绪信号如何转化成买卖规则。

## 7. 常见疑惑释义

- **为什么不用手工特征？** 预训练模型自带语言理解能力，但在金融领域，动词及论元指向的事件主体非常关键，通过 SRL 能让模型更聚焦。
- **因子和文本信息会冲突吗？** 模型把它们拼接后一起输入分类头，让网络自动学习如何权衡。实践中，因子往往能提供“公司基本面”背景，弥补纯文本无法表达的数字。
- **对比学习有何作用？** 遮蔽某个角色再让模型预测，可以鼓励它更好地理解该角色对情绪的影响，同时提升泛化能力。
- **为什么训练集准确率上升而验证集停滞？** 常见原因包括：① **过拟合**——模型记住了训练数据但没有学到可泛化的规律，可通过增加 dropout、提前停止、或引入数据增广缓解；② **训练/验证分布差异**——若两者时间段不同或包含不同的行业，模型会在验证集上遇到未见过的模式，此时可检查划分策略、或在验证集中加入更接近目标场景的数据；③ **学习率设置不当**——若学习率过大，参数在验证集上振荡，可尝试使用调度器或较小的初始学习率。首先确认验证集预处理与训练一致，再结合上述思路逐项排查。

通过以上说明，你可以从宏观上理解 Notebook 的设计逻辑，再根据研究兴趣挑选合适的变体深入实验。
